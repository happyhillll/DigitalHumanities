{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/happyhillll/DigitalHumanities/blob/main/%5BDH%EA%B2%A8%EC%9A%B8%ED%95%99%EA%B5%90%5D_JaneAusten.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsEMnM36pHw_"
      },
      "source": [
        "# 제인 오스틴 대화 데이터 분석 (project-dialogism-novel-corpus)\n",
        "작성 : 김병준(KAIST 디지털인문사회과학센터) / 정서현(KAIST 디지털인문사회과학부)  \n",
        "주의 : 2023 디지털인문학 겨울학교 문학 트랙 day3 코딩 실습 자료입니다. 아직 진행중인 연구이므로 활용에 주의해주십시오."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. 필요 패키지 설치 및 로드\n",
        "상단 메뉴에서 런타임 - 런타임 유형 변경을 눌러 GPU임을 확인"
      ],
      "metadata": {
        "id": "aq054IBypScC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q pca gensim nltk 'spacy[cuda-autodetect]' transformers gdown natsort gutenbergpy"
      ],
      "metadata": {
        "id": "yqTO-AuGpakq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spacy 영어 모델 다운로드(다운로드 속도를 위해 sm(small) 모델 다운)\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "w6E1DeXNqRc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKtsWinmpHxC"
      },
      "outputs": [],
      "source": [
        "# 필요 패키지 load\n",
        "import spacy\n",
        "print(spacy.prefer_gpu()) #GPU 활용\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "nlp.add_pipe('sentencizer')\n",
        "import pandas as pd\n",
        "from pca import pca\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import ast\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "import gensim\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "\n",
        "from transformers import pipeline\n",
        "ekman = pipeline('sentiment-analysis', model='arpanghoshal/EkmanClassifier', device=0, top_k=None)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.dpi\"] = 200 # DPI 고화질로 향상\n",
        "import seaborn as sns\n",
        "import gdown\n",
        "from natsort import natsorted, index_natsorted, order_by_index\n",
        "import gutenbergpy.textget"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PDNC 데이터 github에서 clone\n",
        "# https://github.com/Priya22/project-dialogism-novel-corpus\n",
        "!git clone https://github.com/Priya22/project-dialogism-novel-corpus.git"
      ],
      "metadata": {
        "id": "eTdzZ-wRqui3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtRC7H3VpHxE"
      },
      "source": [
        "### 1. 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu8wpxg1pHxE"
      },
      "source": [
        "##### 제인 오스틴 소설 quote 자료 로드\n",
        "* Emma  \n",
        "* NorthangerAbbey  \n",
        "* Persuasion  \n",
        "* PrideAndPrejudice  \n",
        "* SenseAndSensibility  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPqO1zuPpHxF"
      },
      "outputs": [],
      "source": [
        "# 제인 오스틴 5개 작품(폴더명) 리스트로 만들기\n",
        "folder_list = ['Emma', 'NorthangerAbbey','Persuasion','PrideAndPrejudice','SenseAndSensibility']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVKxwKVipHxF"
      },
      "outputs": [],
      "source": [
        "# df라는 변수에 제인 오스틴 대화 데이터 넣기\n",
        "df = pd.DataFrame()\n",
        "for folder in tqdm(folder_list):\n",
        "    temp = pd.read_csv(f'./project-dialogism-novel-corpus/data/{folder}/quotation_info.csv')\n",
        "    temp['title'] = folder # title 컬럼 추가\n",
        "    df = pd.concat([df,temp],ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3afASaLpHxF"
      },
      "outputs": [],
      "source": [
        "# 대화 데이터 확인\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iHqc5tkpHxG"
      },
      "outputs": [],
      "source": [
        "# 작품별 대화(quote) 수\n",
        "df['title'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHeadSJRpHxG"
      },
      "outputs": [],
      "source": [
        "# subQuotationList : str to list \n",
        "df['subQuotationList'] = df['subQuotationList'].map(lambda x:ast.literal_eval(x))\n",
        "df['subQuotationList']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quoteText와 subQuotationList의 차이 비교\n",
        "pprint(df['quoteText'][5273])\n",
        "pprint(df['subQuotationList'][5273])"
      ],
      "metadata": {
        "id": "kaWapV3hr5lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7Rr2Ek-pHxH"
      },
      "outputs": [],
      "source": [
        "# quoteText를 문장 단위로 분절화 (spacy 모듈 활용)\n",
        "df['sents'] = df['quoteText'].progress_map(lambda x:list(nlp(x).sents))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 분절화 결과 확인\n",
        "df['sents'][0]"
      ],
      "metadata": {
        "id": "m9BPhxODtSIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhYn_0ChpHxH"
      },
      "outputs": [],
      "source": [
        "# 문장 단위로 행 확장 (5278개 행에서 14854행으로 확장)\n",
        "df = df.explode('sents').reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOkhxDUGpHxI"
      },
      "outputs": [],
      "source": [
        "# 캐릭터별 발화 문장 수\n",
        "df.groupby(['title'])['speaker'].value_counts().to_excel('./작품별_인물_발화문장수.xlsx') # 엑셀로 저장\n",
        "df.groupby(['title'])['speaker'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kQrx2c2pHxI"
      },
      "outputs": [],
      "source": [
        "# 작품-인물별 발화 토큰 수\n",
        "df['numOfTokens'] = df['sents'].str.len()\n",
        "df.groupby(['title','speaker'])['numOfTokens'].sum().to_excel('./작품별_인물_발화토큰수.xlsx')\n",
        "df.groupby(['title','speaker'])['numOfTokens'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9M8Gy8cpHxI"
      },
      "outputs": [],
      "source": [
        "# 작품-인물별 발화 글자수(띄어쓰기 포함)\n",
        "df['numOfLetter'] = df['quoteText'].str.len()\n",
        "df.groupby(['title','speaker'])['numOfLetters'].sum().to_excel('./작품별_인물_발화글자수.xlsx')\n",
        "df.groupby(['title','speaker'])['numOfLetters'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i4ri5nupHxJ"
      },
      "outputs": [],
      "source": [
        "df.groupby(['title','speaker']).agg({'speaker':lambda x:x.value_counts(),\n",
        "                                    'numOfTokens':'sum',\n",
        "                                    'numOfLetters':'sum'}).to_excel('./작품별_인물_발화문장토큰글자수.xlsx')\n",
        "\n",
        "df.groupby(['title','speaker']).agg({'speaker':lambda x:x.value_counts(),\n",
        "                                    'numOfTokens':'sum',\n",
        "                                    'numOfLetters':'sum'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sV9_c7KpHxJ"
      },
      "source": [
        "### 2. 토크나이징\n",
        "[유명한 자연어처리 패키지 spaCy](https://spacy.io/)  \n",
        "[품사 tag 참고](https://universaldependencies.org/u/pos/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICUem6aDpHxJ"
      },
      "outputs": [],
      "source": [
        "# 토크나이징 \n",
        "# https://spacy.io/usage/linguistic-features\n",
        "df['tokens'] = df['sents'].progress_map(lambda x:[token.lemma_+'/'+token.pos_ for token in x]) #Lemmatization 처리된 토큰 추출 (https://wikidocs.net/21707)\n",
        "df['tokens']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이징 결과 확인\n",
        "df['tokens'][0]"
      ],
      "metadata": {
        "id": "gLaCagLVwUPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCKAGFgKpHxK"
      },
      "outputs": [],
      "source": [
        "# 상위 n개 Unigram 확인\n",
        "unigram = chain(*df['tokens'].tolist())\n",
        "cnt = Counter(unigram)\n",
        "cnt.most_common(50) # 상위 N개"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 특정 품사만 추출하기"
      ],
      "metadata": {
        "id": "4HPElmTozadB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "allowed_postags = ['ADJ','NOUN','VERB','PROPN','ADV'] # 추출하고 싶은 품사 리스트 (형용사, 명사, 동사, 고유명사, 부사)"
      ],
      "metadata": {
        "id": "usc6QI8Cz-lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['allowed_tokens'] = df['tokens'].map(lambda x:[token for token in x if token.split('/')[1] in allowed_postags])\n",
        "df['allowed_tokens'] "
      ],
      "metadata": {
        "id": "ExR3ZN1Qzrj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EksEcGkpHxK"
      },
      "outputs": [],
      "source": [
        "def cal_unigram(tokens):\n",
        "    unigram = chain(*tokens)\n",
        "    cnt = Counter(unigram)\n",
        "    res = cnt.most_common(50) # 상위 N개\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYcQRK4BpHxK"
      },
      "outputs": [],
      "source": [
        "# 작품 - 캐릭터별 상위 50개 토큰 정리 엑셀로 저장\n",
        "for idx, title in tqdm(enumerate(folder_list)):\n",
        "    df_title = df.loc[df['title']==title]\n",
        "    chas = list(df_title['speaker'].unique())\n",
        "    title_freq = pd.DataFrame()\n",
        "    for cha in chas:\n",
        "        title_freq = pd.concat([title_freq,pd.DataFrame(cal_unigram(df_title.loc[df_title['speaker']==cha,'allowed_tokens'].tolist()),columns=[f'{cha}','freq'])], axis=1)\n",
        "    if idx==0:\n",
        "        title_freq.to_excel('./title_allowed_tokens_freq.xlsx',sheet_name=title,index=None)\n",
        "    else:\n",
        "        with pd.ExcelWriter(f'./title_allowed_tokens_freq.xlsx',mode='a',engine='openpyxl') as writer:\n",
        "            title_freq.to_excel(writer,sheet_name=title,index=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시\n",
        "title_freq"
      ],
      "metadata": {
        "id": "0CNmk_m37I4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 불용어(stopwords) 처리\n",
        "보통 텍스트 마이닝 연구에서 별 의미가 없거나 문법적인 역할만 하는 단어들을 제거하는 것."
      ],
      "metadata": {
        "id": "8fLcPOJK2eUl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z43IF1HlpHxL"
      },
      "outputs": [],
      "source": [
        "# nltk 불용어의 문제 (https://www.nltk.org/), 과연 문학 텍스트에 적용해도 되는가?\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TICuNBdjpHxL"
      },
      "outputs": [],
      "source": [
        "# 상위 n개 Unigram 확인\n",
        "unigram = chain(*df['allowed_tokens'])\n",
        "cnt = Counter(unigram)\n",
        "cnt.most_common(100) # 상위 N개"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwAdYvJUpHxL"
      },
      "outputs": [],
      "source": [
        "stop_words = ['Mr./PROPN','Mrs./PROPN','Miss/PROPN']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmnPzjzSpHxL"
      },
      "outputs": [],
      "source": [
        "# 불용어 제거\n",
        "df['allowed_tokens_stop'] = df['allowed_tokens'].map(lambda x:[t for t in x if not t in stop_words])\n",
        "df['allowed_tokens_stop']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 상위 n개 Unigram 확인\n",
        "unigram = chain(*df['allowed_tokens_stop'])\n",
        "cnt = Counter(unigram)\n",
        "cnt.most_common(100) # 상위 N개"
      ],
      "metadata": {
        "id": "nD_89COM8_CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umeTokHbpHxL"
      },
      "source": [
        "### 3. 감정 분류(Emotion Classification)\n",
        "https://en.wikipedia.org/wiki/Emotion_classification  \n",
        "[GoEmotions](https://ai.googleblog.com/2021/10/goemotions-dataset-for-fine-grained.html)  \n",
        "[GoEmotions를 개량화한 모델 활용](https://huggingface.co/arpanghoshal/EkmanClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GoEmotions에서 ekman(7개 감정으로 경량화) 모델 연습\n",
        "ekman('I cannot agree with you, papa; you know I cannot.') # 영어 문장을 넣어보세요(실습)"
      ],
      "metadata": {
        "id": "mtl8AXcsA0qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 문장의 감정 점수 추출 (3~4분 소요)\n",
        "df['emotions'] = df['sents'].progress_map(lambda x:ekman(str(x)))"
      ],
      "metadata": {
        "id": "thYEE4sdA54D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 확인\n",
        "pprint(df['sents'][0])\n",
        "pprint(df['emotions'][0])"
      ],
      "metadata": {
        "id": "TgyhINGOCgj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 감정 알파벳순으로 정렬 (현재 가장 점수 높은 감정이 맨앞에 있음)\n",
        "df['emotions'] = df['emotions'].map(lambda x:sorted(x[0], key=lambda d: d['label']))\n",
        "df['emotions']"
      ],
      "metadata": {
        "id": "nNWuBvA1Dgw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  감정 테이블 생성(df_emo)\n",
        "df['emotions_scores'] = df['emotions'].map(lambda x:[s['score'] for s in x])\n",
        "df_emo = pd.DataFrame()\n",
        "for emos in tqdm(df['emotions_scores'].tolist()):\n",
        "    temp = pd.DataFrame.from_dict(emos).T\n",
        "    df_emo = pd.concat([df_emo,temp],ignore_index=True)\n",
        "df_emo.columns = ['anger','disgust','fear','joy','neutral','sadness','surprise']\n",
        "df_emo"
      ],
      "metadata": {
        "id": "HVtFv0qbECdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jane Austen 소설의 7개 감정 통계량\n",
        "df_emo.describe()"
      ],
      "metadata": {
        "id": "LYWfU-e5EJ5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jane Austen 소설의 7개 박스 플롯\n",
        "# 박스플롯 이해하기 : https://newsjel.ly/archives/newsjelly/14177\n",
        "sns.boxplot(data = df_emo)"
      ],
      "metadata": {
        "id": "RfrvjqRCEQ_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장-감정 테이블(df_emo)에 화자와 quoteID, 작품명 추가 \n",
        "df_emo['speaker'] = df['speaker']\n",
        "df_emo['quoteID'] = df['quoteID']\n",
        "df_emo['title'] = df['title']\n",
        "df_emo.to_excel('./df_emo.xlsx')\n",
        "df_emo"
      ],
      "metadata": {
        "id": "4ZjF2H1BEZDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 작품/캐릭터별 감정 통계 및 박스플롯 시각화"
      ],
      "metadata": {
        "id": "rJjq-BWFFYvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5개 소설의 주요 캐릭터 7명(총 35명)을 항목별로 정리한 파일 다운로드(feat 정서현 교수님)\n",
        "url = 'https://docs.google.com/uc?id=12nQcV9dugVGo5LS7hoAvF0odO_sJXpg0'\n",
        "file = 'JaneAusten_Characters.xlsx'\n",
        "gdown.download(url,file)"
      ],
      "metadata": {
        "id": "UW6Z3mlDGWGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters_df = pd.read_excel('./JaneAusten_Characters.xlsx')\n",
        "characters_df"
      ],
      "metadata": {
        "id": "Mi0OoDO0FWak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 작품별로 캐릭터 리스트 생성\n",
        "SenseAndSensibility = characters_df.iloc[0,1:].tolist()\n",
        "NorthangerAbbey = characters_df.iloc[1,1:].tolist()\n",
        "PrideAndPrejudice = characters_df.iloc[2,1:].tolist()\n",
        "Emma = characters_df.iloc[3,1:].tolist()\n",
        "Persuasion = characters_df.iloc[4,1:].tolist()\n",
        "characters = list(characters_df.iloc[:,1:].stack().values) # 전체 35명의 캐릭터\n",
        "characters"
      ],
      "metadata": {
        "id": "MCHxmsBxG7d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 작품-캐릭터 딕셔너리 생성\n",
        "title_chas = [{'SenseAndSensibility':SenseAndSensibility},{'NorthangerAbbey':NorthangerAbbey},{'PrideAndPrejudice':PrideAndPrejudice},{'Emma':Emma},{'Persuasion':Persuasion}]\n",
        "title_chas"
      ],
      "metadata": {
        "id": "BzQCPqe4HBS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 작품별로 주요 7명의 캐릭터들의 감정 통계량과 박스플롯 시각화 파일 저장(plots 폴더아래)\n",
        "!mkdir plots # plots 폴더 생성\n",
        "emotions =  ['anger', 'disgust','fear', 'joy','neutral','sadness','surprise']\n",
        "for title_dict in tqdm(title_chas):\n",
        "    chas = list(title_dict.values())[0]\n",
        "    title = list(title_dict.keys())[0]\n",
        "    temp_df = df_emo.loc[df_emo['speaker'].isin(chas)]\n",
        "    # 통계량\n",
        "    temp_df.describe().to_excel(f'./plots/{title}_describe.xlsx')\n",
        "    # 감정별 박스플롯\n",
        "    for emo in emotions:\n",
        "        emo_boxplot = sns.boxplot(x='speaker',y=emo, data=temp_df)\n",
        "        emo_boxplot.set_xticklabels(emo_boxplot.get_xticklabels(), rotation=45)\n",
        "        emo_boxplot_fig = emo_boxplot.get_figure()\n",
        "        emo_boxplot_fig.savefig(f'./plots/{title}_{emo}_boxplot.png', dpi=300, bbox_inches='tight')\n",
        "        emo_boxplot_fig.clf()"
      ],
      "metadata": {
        "id": "N58mxSOIHMXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 작품별 박스플롯\n",
        "for emo in ['anger', 'disgust','fear', 'joy','neutral','sadness','surprise']:\n",
        "    emo_boxplot = sns.boxplot(x='title',y=emo, data=df_emo)\n",
        "    emo_boxplot.set_xticklabels(emo_boxplot.get_xticklabels(), rotation=45)\n",
        "    emo_boxplot_fig = emo_boxplot.get_figure()\n",
        "    emo_boxplot_fig.savefig(f'./plots/title_{emo}_boxplot.png', dpi=300, bbox_inches='tight')\n",
        "    emo_boxplot_fig.clf()"
      ],
      "metadata": {
        "id": "pBfapYWUHuOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 대화 진행에 따른 시계열 감정 추이"
      ],
      "metadata": {
        "id": "qzD8h0lfH7WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_emo['quoteNum'] = df_emo['quoteID'].str.extract('(\\d+)').astype(int)\n",
        "df_emo_quote = df_emo.groupby(['title','quoteNum','speaker']).mean()\n",
        "df_emo_quote"
      ],
      "metadata": {
        "id": "y8bCcFc3IO8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 작품 Emma의 quoteID 진행에 따른 감정 추이 \n",
        "Emma_emo = df_emo_quote.xs('Emma',level='title').reset_index()\n",
        "Emma_emo = Emma_emo.reset_index()\n",
        "Emma_emo['index'] = (Emma_emo['index'] + 1) / len(Emma_emo)\n",
        "Emma_emo"
      ],
      "metadata": {
        "id": "Ay5IIt09HwAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기쁨의 추세선\n",
        "sns.regplot(x='index',y='joy',data=Emma_emo)"
      ],
      "metadata": {
        "id": "KlttGVHyJqpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# line plot\n",
        "Emma_emo.groupby('index').mean()['joy'].plot()"
      ],
      "metadata": {
        "id": "SKdKHB5rJq1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quote 단위가 너무 작기 때문에 감정 변화의 추이를 살펴보기 어려움. 따라서 좀더 큰 범위의 대화 범위를 추가 마킹(feat. 정서현 교수님)\n",
        "# 두개 작품(이성과 감성, 오만과 편견만 추가 marking)\n",
        "url = 'https://docs.google.com/uc?id=1KeoJ3PP5rFcBVdQn9zJBO6u-T2ugOMOt'\n",
        "file = 'SenseAndSensibilityConversationsMarked.xlsx'\n",
        "gdown.download(url,file)\n",
        "\n",
        "url = 'https://docs.google.com/uc?id=1CyviGAW9Ajvt-ONZowyet97emv8AMHWb'\n",
        "file = 'PrideAndPrejudiceConversationsMarked.xlsx'\n",
        "gdown.download(url,file)"
      ],
      "metadata": {
        "id": "oMmfQqZ2J214"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이성과 감성\n",
        "SASCM = pd.read_excel('./SenseAndSensibilityConversationsMarked.xlsx')\n",
        "SASCM #conversationID 추가함"
      ],
      "metadata": {
        "id": "oP8-6sf-Km7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_emo_SS = df_emo.loc[df_emo['title']=='SenseAndSensibility'].reset_index(drop=True)\n",
        "df_emo_SS = df_emo_SS.merge(SASCM[['quoteID','conversationID']],on='quoteID',how='inner')\n",
        "df_emo_SS"
      ],
      "metadata": {
        "id": "WK9PkBoVKt6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이성과 감성 감정 추이\n",
        "df_emo_SS_cID = df_emo_SS.groupby(['conversationID']).mean().iloc[:,:-1] # 평균 활용\n",
        "df_emo_SS_cID.index = natsorted(df_emo_SS_cID.index)\n",
        "df_emo_SS_cID"
      ],
      "metadata": {
        "id": "KrtAvqQqK0ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_emo_SS_cID.plot()"
      ],
      "metadata": {
        "id": "rWOms3oIK7JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 엑셀로 저장\n",
        "df_emo_SS_cID.to_excel('SenseAndSensibility_emo_cID.xlsx')"
      ],
      "metadata": {
        "id": "JmvZS11sLIM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 오만과 편견\n",
        "PAPCM = pd.read_excel('./PrideAndPrejudiceConversationsMarked.xlsx')\n",
        "PAPCM"
      ],
      "metadata": {
        "id": "uhgxkw28MnGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_emo_PP = df_emo.loc[df_emo['title']=='PrideAndPrejudice'].reset_index(drop=True)\n",
        "df_emo_PP = df_emo_PP.merge(PAPCM[['quoteID','conversationID']],on='quoteID',how='inner')"
      ],
      "metadata": {
        "id": "YvWtfr2MMw4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 오만과 편견 감정 추이\n",
        "df_emo_PP_cID = df_emo_PP.groupby(['conversationID']).mean().iloc[:,:-1] # 평균 활용\n",
        "df_emo_PP_cID.index = natsorted(df_emo_PP_cID.index)\n",
        "df_emo_PP_cID"
      ],
      "metadata": {
        "id": "GVkFTR0zMyR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_emo_PP_cID.plot()"
      ],
      "metadata": {
        "id": "QBeUsuhCM-Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 엑셀로 저장\n",
        "df_emo_PP_cID.to_excel('PrideAndPrejudice_emo_cID.xlsx')"
      ],
      "metadata": {
        "id": "8X-3ws9ZNAzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. PCA(주성분분석)\n",
        "7개의 감정을 2개의 축으로 축소하여 어떤 감정이 중요한 변수인지 확인하는 방법  \n",
        "참고문헌 : [김병준, 전봉관 and 이원재. (2017). 비평 언어의 변동: 문예지 비평 텍스트에 나타난 개념단어의 변동 양상, 1995~2015. 현대문학의 연구, 61](https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002201115)"
      ],
      "metadata": {
        "id": "q17gTi0xNL9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 주요 35명의 캐릭터만 활용\n",
        "df_emo_main = df_emo[df_emo['speaker'].isin(characters)].reset_index(drop=True).iloc[:,:-1]\n",
        "df_emo_main"
      ],
      "metadata": {
        "id": "tinBcRnCNJyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주요 캐릭터들의 감정 평균\n",
        "char_emo = df_emo_main.groupby(['speaker']).mean()\n",
        "# char_emo = char_emo.reset_index()\n",
        "char_emo"
      ],
      "metadata": {
        "id": "rh5GYFXsNSHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the data towards 2 PCs\n",
        "sents_cha_model = pca(n_components=2)"
      ],
      "metadata": {
        "id": "rxn92_i_NYuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit transform\n",
        "X = df_emo_main.iloc[:,:7]\n",
        "y = df_emo_main.iloc[:,9]\n",
        "labels = df_emo_main.iloc[:,:7].columns.tolist()\n",
        "# results = model.fit_transform(X,col_labels=char_emo.iloc[:,1:].columns,row_labels=y)\n",
        "sents_cha_results = sents_cha_model.fit_transform(X, col_labels=labels, row_labels=y)"
      ],
      "metadata": {
        "id": "5ztDeL4GNkLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cumulative explained variance\n",
        "print(sents_cha_model.results['explained_var'])"
      ],
      "metadata": {
        "id": "RuwY7lJfNlXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explained variance per PC\n",
        "print(sents_cha_model.results['variance_ratio'])"
      ],
      "metadata": {
        "id": "E3IGOU2FNnlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D plot\n",
        "fig, ax = sents_cha_model.scatter(label=None)"
      ],
      "metadata": {
        "id": "SmbNkIrHNooi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents_cha_model.biplot(cmap=None, label=None, legend=False)"
      ],
      "metadata": {
        "id": "o3V7AJkxNqID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sents_cha_model.results['topfeat']"
      ],
      "metadata": {
        "id": "QB9pztDMNs0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 캐릭터들의 감정 평균 활용 PCA\n",
        "cha_model = pca(n_components=2)\n",
        "cha_results = cha_model.fit_transform(char_emo)"
      ],
      "metadata": {
        "id": "oUmkfGMaNvSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# biplot\n",
        "cha_model.biplot(cmap=None, label=None, legend=False)"
      ],
      "metadata": {
        "id": "qcJi6f6sN7VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인물들의 감정 평균값을 기반으로한 지형도\n",
        "cha_model.scatter()"
      ],
      "metadata": {
        "id": "0yqnCuxBN2dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outlier\n",
        "cha_model.scatter(SPE=True)"
      ],
      "metadata": {
        "id": "w2O4xooNN3NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 네트워크 Edge list 만들기 (Gephi, networkX에서 활용 가능)"
      ],
      "metadata": {
        "id": "ow9Smh6v76Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_net = pd.DataFrame()\n",
        "for folder in tqdm(folder_list):\n",
        "    temp = pd.read_csv(f'./project-dialogism-novel-corpus/data/{folder}/quotation_info.csv')\n",
        "    temp['title'] = folder\n",
        "    df_net = pd.concat([df_net,temp],ignore_index=True)"
      ],
      "metadata": {
        "id": "8DYrty088Blh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 청자-화자 Edge list 생성"
      ],
      "metadata": {
        "id": "rtmtbAnj8Li3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# addressees : str to list \n",
        "df_net['addressees'] = df_net['addressees'].map(lambda x:ast.literal_eval(x))"
      ],
      "metadata": {
        "id": "07GcyVXC8JZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# edge weight 는 1 / 청자수\n",
        "# A화자에 B,C 청자가 2명이라면 해당 edge list의 weight는 각 0.5\n",
        "df_net['weight'] = 1 / df_net['addressees'].str.len()\n",
        "df_net['weight']"
      ],
      "metadata": {
        "id": "aaK8RmN88Oro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_net = df_net.explode('addressees').reset_index(drop=True)\n",
        "df_net"
      ],
      "metadata": {
        "id": "zIm-t1wt8THr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인\n",
        "df_net[['title','quoteID','speaker','addressees','weight']]"
      ],
      "metadata": {
        "id": "2WUYjeA48aDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 작품별 edge list 엑셀로 저장\n",
        "* network 폴더에 저장"
      ],
      "metadata": {
        "id": "AL0aWiRf8ck6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir network\n",
        "for folder in tqdm(folder_list):\n",
        "    Edge = df_net.loc[df_net['title']==folder,['quoteID','speaker','addressees','weight']].reset_index(drop=True)\n",
        "    Edge.columns = ['quoteID','source','target','weight']\n",
        "    Edge.to_excel(f'./network/{folder}_edge.xlsx',index=None)"
      ],
      "metadata": {
        "id": "toZ_p85u8cKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인\n",
        "Edge"
      ],
      "metadata": {
        "id": "FYmynmgf8pwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. 구텐베르크 프로젝트 가져오기\n",
        "[Project Gutenberg](https://www.gutenberg.org/)  \n",
        "[파이썬에서 구텐베르크 프로젝트 자료 자동 수집(gutenbergpy)](https://github.com/raduangelescu/gutenbergpy)"
      ],
      "metadata": {
        "id": "kjSu1cfO36Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def usage_example(id):\n",
        "    # This gets a book by its gutenberg id number\n",
        "    raw_book = gutenbergpy.textget.get_text_by_id(id) # with headers\n",
        "    clean_book = gutenbergpy.textget.strip_headers(raw_book) # without headers\n",
        "    return clean_book, raw_book"
      ],
      "metadata": {
        "id": "9iSsD26D4ruS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필경사 바틀비(11231)\n",
        "# https://www.gutenberg.org/ebooks/11231\n",
        "cleaned_book, raw_book = usage_example(11231)"
      ],
      "metadata": {
        "id": "Nupdzwgz4jAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각종 메타정보 포함한 버전(''The Project Gutenberg eBook of Bartleby, The Scrivener, by Herman Melvil ...')\n",
        "pprint(raw_book)"
      ],
      "metadata": {
        "id": "oXTmuFjz9nKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각종 메타 정보 삭제한 버전\n",
        "pprint(cleaned_book)"
      ],
      "metadata": {
        "id": "pUwsOj5j9u6y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "spacy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "01631d6fcca472985baccf9f99ef137086ef9b63bd3146194233956ccc0284ca"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}